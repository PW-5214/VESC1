{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28332a5-9bb6-4b1c-9cb9-04c7fc7e1053",
   "metadata": {},
   "source": [
    "### Text Preprocessing - Implement text preprocessing techniques, including tokenization and\n",
    "### normalization, and apply it to any text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0324112c-0a65-4f3f-9989-8b1712401843",
   "metadata": {},
   "outputs": [],
   "source": [
    "para =\"Natural Language Processing is a field that combines computer science, artificial intelligence and language studies. It helps computers understand, process and create human language in a way that makes sense and is useful.It can use two domains.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc005b2b-b1f8-4004-8270-e2f837be770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing is a field that combines computer science, artificial intelligence and language studies. It helps computers understand, process and create human language in a way that makes sense and is useful.It can use two domains.\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e9a0e-c0be-4d6f-abe9-5b06332ed4f5",
   "metadata": {},
   "source": [
    "### 1.Tokenization\n",
    "### a) Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7edd974e-53e8-4530-b40a-598f42907873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/admin1/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b842ff1-ce03-4bdc-9af6-d8c0e9c2de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8c01077-ba2e-4984-b61c-4992f5c60ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in para:\n",
    "    tokens = word_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cef0b688-4370-4f37-8c45-c0f2b72b4bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'that',\n",
       " 'combines',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'and',\n",
       " 'language',\n",
       " 'studies',\n",
       " '.',\n",
       " 'It',\n",
       " 'helps',\n",
       " 'computers',\n",
       " 'understand',\n",
       " ',',\n",
       " 'process',\n",
       " 'and',\n",
       " 'create',\n",
       " 'human',\n",
       " 'language',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'sense',\n",
       " 'and',\n",
       " 'is',\n",
       " 'useful.It',\n",
       " 'can',\n",
       " 'use',\n",
       " 'two',\n",
       " 'domains',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf645e-62ab-4afa-91c6-dd384a1df0aa",
   "metadata": {},
   "source": [
    "### b) Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19e68968-0867-431e-b59f-39560033c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentence = sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aadbd061-4aad-4176-81fb-c7a583dfd240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Processing is a field that combines computer science, artificial intelligence and language studies.',\n",
       " 'It helps computers understand, process and create human language in a way that makes sense and is useful.It can use two domains.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ffeca8-d3cf-4d8a-b3e4-d2c3cc3ed34f",
   "metadata": {},
   "source": [
    "### c)Punctuation Seperation Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d677ad7-8e6d-406b-a8b3-bc18e846ec12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'that',\n",
       " 'combines',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'and',\n",
       " 'language',\n",
       " 'studies',\n",
       " '.',\n",
       " 'It',\n",
       " 'helps',\n",
       " 'computers',\n",
       " 'understand',\n",
       " ',',\n",
       " 'process',\n",
       " 'and',\n",
       " 'create',\n",
       " 'human',\n",
       " 'language',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'sense',\n",
       " 'and',\n",
       " 'is',\n",
       " 'useful',\n",
       " '.',\n",
       " 'It',\n",
       " 'can',\n",
       " 'use',\n",
       " 'two',\n",
       " 'domains',\n",
       " '.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(para)   ## apostrope(') also seperated and also other punctuation has sepearate token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d701818c-7c12-47f5-ba20-992c58dcb839",
   "metadata": {},
   "source": [
    "### d)TreebankTokenizer     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e25abb17-851b-4649-ac55-0c7cb03dc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "word = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e1472d23-6ce0-4748-9528-d4222eaff99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=word.tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d91bc74-f345-4384-81d8-48ee736b80cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'that',\n",
       " 'combines',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'and',\n",
       " 'language',\n",
       " 'studies.',\n",
       " 'It',\n",
       " 'helps',\n",
       " 'computers',\n",
       " 'understand',\n",
       " ',',\n",
       " 'process',\n",
       " 'and',\n",
       " 'create',\n",
       " 'human',\n",
       " 'language',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'sense',\n",
       " 'and',\n",
       " 'is',\n",
       " 'useful.It',\n",
       " 'can',\n",
       " 'use',\n",
       " 'two',\n",
       " 'domains',\n",
       " '.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564377fb-a227-4632-8330-82200b555217",
   "metadata": {},
   "source": [
    "### 2.Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce30a6-4650-4a24-b417-8a259e46b7da",
   "metadata": {},
   "source": [
    "### a)Porter Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6a8cb1b-6be6-478a-a06c-42162cafaed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "968ed2b4-7fbe-49d6-81b1-0276b151feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "13382dfc-5833-435b-ac8d-28c1266afd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural------->natur\n",
      "Language------->languag\n",
      "Processing------->process\n",
      "is------->is\n",
      "a------->a\n",
      "field------->field\n",
      "that------->that\n",
      "combines------->combin\n",
      "computer------->comput\n",
      "science------->scienc\n",
      ",------->,\n",
      "artificial------->artifici\n",
      "intelligence------->intellig\n",
      "and------->and\n",
      "language------->languag\n",
      "studies.------->studies.\n",
      "It------->it\n",
      "helps------->help\n",
      "computers------->comput\n",
      "understand------->understand\n",
      ",------->,\n",
      "process------->process\n",
      "and------->and\n",
      "create------->creat\n",
      "human------->human\n",
      "language------->languag\n",
      "in------->in\n",
      "a------->a\n",
      "way------->way\n",
      "that------->that\n",
      "makes------->make\n",
      "sense------->sens\n",
      "and------->and\n",
      "is------->is\n",
      "useful.It------->useful.it\n",
      "can------->can\n",
      "use------->use\n",
      "two------->two\n",
      "domains------->domain\n",
      ".------->.\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(w +\"------->\"+ stemming.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e5743-8cb2-4be8-86a8-79728503fc48",
   "metadata": {},
   "source": [
    "### b)RegexpStemmer-Regular Expression Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f1443e9d-f1d1-4b7b-a894-eb240fafb5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2c2fb7d-3568-4acc-af15-a72d68485f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating -> eat\n",
      "writes -> write\n",
      "readable -> read\n",
      "running -> runn\n"
     ]
    }
   ],
   "source": [
    "# Initialize RegexpStemmer to remove suffixes like 'ing', 's', 'e', 'able'\n",
    "\n",
    "reg_stem = RegexpStemmer('ing$|s$|e$|able$')\n",
    "\n",
    "words1 = ['eating', 'writes', 'readable', 'running']\n",
    "\n",
    "for word1 in words1:\n",
    "    print(word1 + \" -> \" + reg_stem.stem(word1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215ac0a-9bdb-4b3b-a0e5-64dd7c752595",
   "metadata": {},
   "source": [
    "### c)Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1ce948ca-ddab-4e0b-986f-381518962e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e2da2fcf-683a-41a5-a42b-797909581b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural -> natur\n",
      "Language -> languag\n",
      "Processing -> process\n",
      "is -> is\n",
      "a -> a\n",
      "field -> field\n",
      "that -> that\n",
      "combines -> combin\n",
      "computer -> comput\n",
      "science -> scienc\n",
      ", -> ,\n",
      "artificial -> artifici\n",
      "intelligence -> intellig\n",
      "and -> and\n",
      "language -> languag\n",
      "studies. -> studies.\n",
      "It -> it\n",
      "helps -> help\n",
      "computers -> comput\n",
      "understand -> understand\n",
      ", -> ,\n",
      "process -> process\n",
      "and -> and\n",
      "create -> creat\n",
      "human -> human\n",
      "language -> languag\n",
      "in -> in\n",
      "a -> a\n",
      "way -> way\n",
      "that -> that\n",
      "makes -> make\n",
      "sense -> sens\n",
      "and -> and\n",
      "is -> is\n",
      "useful.It -> useful.it\n",
      "can -> can\n",
      "use -> use\n",
      "two -> two\n",
      "domains -> domain\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(w + \" -> \" + snowball_stemmer.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "76f0b74e-7028-442d-8fa2-b936cdcaed0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fair'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem(\"fairly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7701cf-38b7-4305-8bdc-24f493628949",
   "metadata": {},
   "source": [
    "### 3.Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cb2bbe85-7c71-4d72-83ac-2349f6bd14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bbe48619-89cf-42b3-acb1-1f92029314c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "13558ce5-20eb-451e-958f-b47d8161b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/admin1/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a7fdf24a-659b-435e-87f8-7644b406a1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural---->Natural\n",
      "Language---->Language\n",
      "Processing---->Processing\n",
      "is---->be\n",
      "a---->a\n",
      "field---->field\n",
      "that---->that\n",
      "combines---->combine\n",
      "computer---->computer\n",
      "science---->science\n",
      ",---->,\n",
      "artificial---->artificial\n",
      "intelligence---->intelligence\n",
      "and---->and\n",
      "language---->language\n",
      "studies.---->studies.\n",
      "It---->It\n",
      "helps---->help\n",
      "computers---->computers\n",
      "understand---->understand\n",
      ",---->,\n",
      "process---->process\n",
      "and---->and\n",
      "create---->create\n",
      "human---->human\n",
      "language---->language\n",
      "in---->in\n",
      "a---->a\n",
      "way---->way\n",
      "that---->that\n",
      "makes---->make\n",
      "sense---->sense\n",
      "and---->and\n",
      "is---->be\n",
      "useful.It---->useful.It\n",
      "can---->can\n",
      "use---->use\n",
      "two---->two\n",
      "domains---->domains\n",
      ".---->.\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(w+\"---->\"+lemma.lemmatize(w,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "474d4fc1-4736-4351-b41e-3f6d3012b379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eat\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n",
      "history---->history\n",
      "finally---->finally\n",
      "finalize---->finalize\n"
     ]
    }
   ],
   "source": [
    "words2 = [\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalize\"]\n",
    "for word in words2:\n",
    "    print(word+\"---->\"+lemma.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f040083-57c9-491e-b3e8-a40902f52b05",
   "metadata": {},
   "source": [
    "### 4.Stopword Removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "49d3846a-6890-4d79-8dd2-044ef14f8b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/admin1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1189856f-38f2-446a-9051-3a55571d197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d698cc-f872-4906-ac90-6056adaa26cf",
   "metadata": {},
   "source": [
    "### a) Stemming use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea33a1e-5a9e-4b52-bab5-2535bbaff243",
   "metadata": {},
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "98aea6e9-ce20-48e8-894d-bf7255a9d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "para =\"Natural Language Processing is a field that combines computer science, artificial intelligence and language studies. It helps computers understand, process and create human language in a way that makes sense and is useful.It can use two domains.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cc176437-96a8-405b-83c2-e7191b30b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "45a1df35-7811-4bdf-be3d-7dd063ecf560",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english'))]\n",
    "    sentences[i] = \" \".join(words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "29454efe-b75b-4b0b-9d23-f2e3e5a5d838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natur languag process field combin comput scienc , artifici intellig languag studi .',\n",
       " 'help comput understand , process creat human languag way make sens useful.it use two domain .']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c64e33-cf69-4d6a-9d80-d987fb8172f2",
   "metadata": {},
   "source": [
    "### b)Lemmatization used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "00852d60-cacd-4e9f-9222-fc68dfe073c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "para =\"Natural Language Processing is a field that combines computer science, artificial intelligence and language studies. It helps computers understand, process and create human language in a way that makes sense and is useful.It can use two domains.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a7deccff-cc22-4256-ac28-b99a7fca9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "626f5e21-454b-433c-bd0b-fe79852ffcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply the lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word.lower(),pos='v') for word in words if word.lower() not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d7defe71-af0f-48e4-8b02-8b31137ab9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural language process field combine computer science , artificial intelligence language study .',\n",
       " 'help computers understand , process create human language way make sense useful.it use two domains .']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe9252-0d48-4b7c-84d4-1bf7f3b3a7db",
   "metadata": {},
   "source": [
    "### 5.Uppercase and Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f2d23787-2f58-46a6-807a-fc879a59b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "para =\"Natural Language Processing is a field that combines computer science, artificial intelligence and language studies. It helps computers understand, process and create human language in a way that makes sense and is useful.It can use two domains.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "727d5d43-88cb-4e25-ade7-cd7b5c9466e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bdc8f1c6-7a49-4f7c-929c-c0d2b39287f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural==========>natural\n",
      "Language==========>language\n",
      "Processing==========>processing\n",
      "is==========>is\n",
      "a==========>a\n",
      "field==========>field\n",
      "that==========>that\n",
      "combines==========>combines\n",
      "computer==========>computer\n",
      "science==========>science\n",
      ",==========>,\n",
      "artificial==========>artificial\n",
      "intelligence==========>intelligence\n",
      "and==========>and\n",
      "language==========>language\n",
      "studies==========>studies\n",
      ".==========>.\n",
      "It==========>it\n",
      "helps==========>helps\n",
      "computers==========>computers\n",
      "understand==========>understand\n",
      ",==========>,\n",
      "process==========>process\n",
      "and==========>and\n",
      "create==========>create\n",
      "human==========>human\n",
      "language==========>language\n",
      "in==========>in\n",
      "a==========>a\n",
      "way==========>way\n",
      "that==========>that\n",
      "makes==========>makes\n",
      "sense==========>sense\n",
      "and==========>and\n",
      "is==========>is\n",
      "useful.It==========>useful.it\n",
      "can==========>can\n",
      "use==========>use\n",
      "two==========>two\n",
      "domains==========>domains\n",
      ".==========>.\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"==========>\"+word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4fb7b716-6506-4935-a035-50a7cc8a69d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural==========>NATURAL\n",
      "Language==========>LANGUAGE\n",
      "Processing==========>PROCESSING\n",
      "is==========>IS\n",
      "a==========>A\n",
      "field==========>FIELD\n",
      "that==========>THAT\n",
      "combines==========>COMBINES\n",
      "computer==========>COMPUTER\n",
      "science==========>SCIENCE\n",
      ",==========>,\n",
      "artificial==========>ARTIFICIAL\n",
      "intelligence==========>INTELLIGENCE\n",
      "and==========>AND\n",
      "language==========>LANGUAGE\n",
      "studies==========>STUDIES\n",
      ".==========>.\n",
      "It==========>IT\n",
      "helps==========>HELPS\n",
      "computers==========>COMPUTERS\n",
      "understand==========>UNDERSTAND\n",
      ",==========>,\n",
      "process==========>PROCESS\n",
      "and==========>AND\n",
      "create==========>CREATE\n",
      "human==========>HUMAN\n",
      "language==========>LANGUAGE\n",
      "in==========>IN\n",
      "a==========>A\n",
      "way==========>WAY\n",
      "that==========>THAT\n",
      "makes==========>MAKES\n",
      "sense==========>SENSE\n",
      "and==========>AND\n",
      "is==========>IS\n",
      "useful.It==========>USEFUL.IT\n",
      "can==========>CAN\n",
      "use==========>USE\n",
      "two==========>TWO\n",
      "domains==========>DOMAINS\n",
      ".==========>.\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"==========>\"+word.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38762708-25b5-4929-beed-920308c4839c",
   "metadata": {},
   "source": [
    "#### 6.Number to text conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "439371d8-ee7d-4c0e-88df-91377348fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f45c4a8d-de4b-48d8-9dd3-ed3aa89ef189",
   "metadata": {},
   "outputs": [],
   "source": [
    "para =\"Natural Language Processing is a field that combines computer science, artificial intelligence and language studies. It helps computers understand, process and create human language in a way that makes sense and is useful.It can use two domains.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c325f909-bb22-4dfe-8601-5e534f3b7761",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "95a465e4-0fcd-4912-ba0c-3d4e0539a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    nums = [num for num in words if word == type(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1e4750a6-8b3c-47f7-81f4-0b570799f1a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidOperation",
     "evalue": "[<class 'decimal.ConversionSyntax'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidOperation\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[212], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(word\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==========>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[43mnum2words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/num2words/__init__.py:102\u001b[0m, in \u001b[0;36mnum2words\u001b[0;34m(number, ordinal, lang, to, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m converter \u001b[38;5;241m=\u001b[39m CONVERTER_CLASSES[lang]\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(number, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 102\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr_to_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# backwards compatible\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ordinal:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/num2words/base.py:101\u001b[0m, in \u001b[0;36mNum2Word_Base.str_to_number\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstr_to_number\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDecimal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInvalidOperation\u001b[0m: [<class 'decimal.ConversionSyntax'>]"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"==========>\"+num2words(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374455ca-d340-4ed3-bc04-f823288eb3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
